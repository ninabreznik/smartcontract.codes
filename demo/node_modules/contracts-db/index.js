const SDK = require('dat-sdk')
const RAI = require('random-access-idb')
const { Hypercore, Hyperdrive, resolveName, deleteStorage, destroy } = SDK()
const Idbkv = require('idb-kv')
let store = new Idbkv('example-store')
let samples = require('./samples')

var ids = 1
const cancelled = {}
window.store = store

module.exports = contractsDB

function contractsDB (daturl, pageSize) {
  async function getSamples (cb) {
    let sampleContracts = []
    const beginnerContracts = JSON.parse(samples)['beginners']
    for(var i = 0; i < beginnerContracts.length; i++) {
      const name = beginnerContracts[i]
      const url = `${window.location.origin}/demo/node_modules/contracts-db/sampleContracts/${name}.sol`
      const file = await fetch(url)
      const code = await file.text()
      const url1 = `${window.location.origin}/demo/node_modules/contracts-db/samples.json`
      const jsonFile = await fetch(url1)
      const jsonData = await jsonFile.text()
      sampleContracts.push({
        source: code,
        title: name,
        hash: '0x0000000000000000000000',
        metadata: jsonData
      })
    }
    cb(null, sampleContracts)
  }
  // ADD MOLOCH DAO - for the demo @TODO remove after the demo
  // const moloch = require('./moloch-demo.sol')
  // contracts.push({
  //   source: moloch,
  //   title: 'Moloch.sol',
  //   hash: '0x1234567345678903456'
  // })

  const archive = Hyperdrive(daturl, { storage: RAI })
  return { search, list, get, cancel, getPage, getPagesCount, getSamples }

  function search (query, notify) {
    const id = ids++
    setTimeout(() => {
      list((err, allPaths) => {
        if (!cancelled[id]) {
          notify({ type: 'progress', id, body: [0, allPaths.length]})
        }
        if (err) console.error(err)
        searchData(allPaths, (err, contract, progress) => {
          if (err) console.error(err)
          var temp = normalizeWS(contract.source)
          var formattedQuery = normalizeWS(query)
          if (temp.includes(formattedQuery)) {
            if (!cancelled[id]) {
              notify({
                type: 'searchResult',
                id,
                body: contract.path
              })
            }
          }
          if (!cancelled[id]) {
            notify({ type: 'progress', id, body: progress })
          }
        })
      })
    }, 0)
    return id
  }

  function normalizeWS(s) {
    // searchInput.replace(/\n. |\r/g, "")
    s = s.match(/\S+/g);
    return s ? s.join(' ') : '';
  }
  function cancel (id) {
    cancelled[id] = true
  }
  function reallyReady (archive, cb) {
    if (archive.metadata.peers.length) {
      archive.metadata.update({ ifAvailable: true }, cb)
    } else {
      archive.metadata.once('peer-add', () => {
        archive.metadata.update({ ifAvailable: true }, cb)
      })
    }
  }
  async function getPage (page, done) {
    const key = `page-${page}`
    const results =  await store.get(key)
    return done(null, results)
  }
  async function getPagesCount (done) {
    const results = await store.get('pagesCount')
    return done(null, results)
  }
  async function list (done) {
    const results =  await store.get('filepaths')
    if (results) return done(null, results)
    reallyReady(archive, () => {
      archive.readdir('.', (err, filepaths) => {
        if (err) return done(err)
        storeToIndexDB(filepaths)
        done(null, filepaths)
      })
    })
  }
  function storeToIndexDB (filepaths) {
    console.log(`Storing to Indexed DB: ${filepaths}`)
    store.set('filepaths', filepaths )
    store.set('pagesCount', Math.floor(filepaths.length/pageSize))
    let chunkedArr = chunk(filepaths, pageSize)
    for(var i=0; i<chunkedArr.length; i++) {
      store.set(`page-${i+1}`,
        { timestamp: new Date(), filepaths: chunkedArr[i] })
    }
  }
  function chunk(array, size) {
    const chunkedArr = []
    let index = 0
    while (index < array.length) {
      chunkedArr.push(array.slice(index, size + index))
      index += size
    }
    return chunkedArr
  }
  function get (filepaths, done) {
    filepaths = [].concat(filepaths) // if single path, make array
    const contracts = []
    const counter = filepaths.length
    for (var i=0; i<counter; i++) {
      getFile(contracts, counter, filepaths[i], done)
    }
  }
  function getFile (contracts, counter, filepath, done) {
    archive.readFile(filepath, 'utf8', (err, result) => {
      if (err) return done(err) // console.log(err)
      const data = JSON.parse(result)
      contracts.push({
        source: data.sourceCode,
        title: data.contractName,
        hash: data.address,
        metadata: data
      })
      //console.log(`Source codes retreived: ${contracts.length}`)
      if (counter === contracts.length) done(null, contracts)
    })
  }
  function searchData (filepaths, next) {
    const contracts = []
    const counter = filepaths.length
    if (filepaths) {
      for (var i=0; i<counter; i++) {
        getSearchFile(contracts, counter, filepaths[i], next)
      }
    }
  }

  function getSearchFile (contracts, counter, filepath, next) {
    archive.readFile(filepath, 'utf8', (err, result) => {
      if (err) return done(err) // console.log(err)
      const data = JSON.parse(result)
      const contract = {
        source: data.sourceCode,
        path: filepath,
        metadata: data
      }
      contracts.push(contract)
      console.log(`Contracts searched: ${contracts.length}`)
      return next(err, contract, [contracts.length, counter])
    })
  }

}
